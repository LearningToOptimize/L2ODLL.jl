<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Math Background · L2ODLL.jl</title><meta name="title" content="Math Background · L2ODLL.jl"/><meta property="og:title" content="Math Background · L2ODLL.jl"/><meta property="twitter:title" content="Math Background · L2ODLL.jl"/><meta name="description" content="Documentation for L2ODLL.jl."/><meta property="og:description" content="Documentation for L2ODLL.jl."/><meta property="twitter:description" content="Documentation for L2ODLL.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/wider.css" rel="stylesheet" type="text/css"/><link href="../../assets/redlinks.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">L2ODLL.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Math Background</a><ul class="internal"><li><a class="tocitem" href="#Math-Background"><span>Math Background</span></a></li></ul></li><li><a class="tocitem" href="../public/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Math Background</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Math Background</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/LearningToOptimize/L2ODLL.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/LearningToOptimize/L2ODLL.jl/blob/main/docs/src/markdown/math_background.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h2 id="Math-Background"><a class="docs-heading-anchor" href="#Math-Background">Math Background</a><a id="Math-Background-1"></a><a class="docs-heading-anchor-permalink" href="#Math-Background" title="Permalink"></a></h2><h3 id="Decomposition"><a class="docs-heading-anchor" href="#Decomposition">Decomposition</a><a id="Decomposition-1"></a><a class="docs-heading-anchor-permalink" href="#Decomposition" title="Permalink"></a></h3><p>In DLL, the primal constraints (dual variables) are decomposed into a predicted set and a completed set. Consider the primal-dual pair:</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \min\nolimits_{x} &amp; c^\top x
\\
&amp; \;\;\text{s.t.} &amp; Ax + b \in \mathcal{C}
\\
&amp; &amp; x \in \mathbb{R}^n
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \max\nolimits_{y} &amp; - b^\top y
\\
&amp; \;\;\text{s.t.} &amp; A^\top y = c
\\
&amp; &amp; y \in \mathcal{C}^*
\end{aligned}
\end{equation}\]</p><p>After the decomposition, we have:</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \min\nolimits_{x} &amp; c^\top x
\\
&amp; \;\;\text{s.t.} &amp; Ax + b \in \mathcal{C}
\\
&amp; \;\;\phantom{\text{s.t.}} &amp; Hx + h \in \mathcal{K}
\\
&amp; &amp; x \in \mathbb{R}^n
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \max\nolimits_{y} &amp; - b^\top y
\\
&amp; \;\;\text{s.t.} &amp; A^\top y + H^\top z = c
\\
&amp; &amp; y \in \mathcal{C}^*,\; z \in \mathcal{K}^*
\end{aligned}
\end{equation}\]</p><p>Then, the completion model is:</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \max\nolimits_{z} &amp; - h^\top z - b^\top y
\\
&amp; \;\;\text{s.t.} &amp; H z = c - A^\top y
\\
&amp; &amp; z \in \mathcal{K}^*
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \min\nolimits_{x} &amp; (c-A^\top y)^\top x
\\
&amp; \;\;\phantom{\text{s.t.}} &amp; Hx + h \in \mathcal{K}
\\
&amp; &amp; x \in \mathbb{R}^n
\end{aligned}
\end{equation}\]</p><p>To train the neural network, we need the gradient of the optimal value with respect to the predicted <span>$y$</span>. This is <span>$\nabla_y = -b-Ax$</span> where <span>$x$</span> is the optimal dual solution corresponding to the affine constraints in the completion model. In the special cases below, we specify just the expression for <span>$x$</span> in this formula.</p><h4 id="Bounded-Decomposition"><a class="docs-heading-anchor" href="#Bounded-Decomposition">Bounded Decomposition</a><a id="Bounded-Decomposition-1"></a><a class="docs-heading-anchor-permalink" href="#Bounded-Decomposition" title="Permalink"></a></h4><p>When all primal variables have finite upper and lower bounds, a natural way to decompose the constraints is to have <span>$z$</span> correspond to the bound constraints, and <span>$y$</span> correspond to the main constraints, i.e.</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \min\nolimits_{x} &amp; c^\top x
\\
&amp; \;\;\text{s.t.} &amp; Ax + b \in \mathcal{C}
\\
&amp; &amp; l \leq x \leq u
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \max\nolimits_{y,z_l,z_u} &amp; - b^\top y - l^\top z_l - u^\top z_u
\\
&amp; \;\;\text{s.t.} &amp; A^\top y + z_l + z_u = c
\\
&amp; &amp; y \in \mathcal{C}^*,\; z_l \in \mathbb{R}_+^n,\; z_u \in \mathbb{R}_-^n
\end{aligned}
\end{equation}\]</p><p>Then, the completion model is:</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \max\nolimits_{z_l,z_u} &amp; - l^\top z_l - u^\top z_u - b^\top y
\\
&amp; \;\;\text{s.t.} &amp; z_l + z_u = c - A^\top y
\\
&amp; &amp; z_l \in \mathbb{R}_+^n,\; z_u \in \mathbb{R}_-^n
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \min\nolimits_{x} &amp; (c-A^\top y)^\top x
\\
&amp; &amp; l \leq x \leq u
\end{aligned}
\end{equation}\]</p><p>This model admits a closed form solution, <span>$z_l = |c-A^\top y|^+$</span> and <span>$z_u = -|c-A^\top y|^-$</span>. Furthermore, the <span>$x$</span> that defines the (sub-)gradient is given element-wise by <span>$l$</span> if <span>$c-A^\top y &gt; 0$</span>, <span>$u$</span> if <span>$c-A^\top y &lt; 0$</span>, and <span>$x\in[l,u]$</span> otherwise.</p><h4 id="(Strictly)-Convex-QP"><a class="docs-heading-anchor" href="#(Strictly)-Convex-QP">(Strictly) Convex QP</a><a id="(Strictly)-Convex-QP-1"></a><a class="docs-heading-anchor-permalink" href="#(Strictly)-Convex-QP" title="Permalink"></a></h4><p>In the convex QP case, the primal has a strictly convex quadratic objective function, i.e. <span>$Q\succ 0$</span>. In that case it is natural to use the main constraints as the predicted set and to complete the quadratic slack dual variables.</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \min\nolimits_{x} &amp; x^\top Q x + c^\top x
\\
&amp; \;\;\text{s.t.} &amp; Ax + b \in \mathcal{C}
\\
&amp; &amp; x \in \mathbb{R}^n
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \max\nolimits_{y} &amp; - b^\top y - z^\top Q z
\\
&amp; \;\;\text{s.t.} &amp; A^\top y + 2Qz = c
\\
&amp; &amp; y \in \mathcal{C}^*,\; z \in \mathbb{R}^n
\end{aligned}
\end{equation}\]</p><p>Then, the completion model is:</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \max\nolimits_{z} &amp; - z^\top Q z - b^\top y
\\
&amp; \;\;\text{s.t.} &amp; Q z = \frac{1}{2}(c - A^\top y)
\\
&amp; &amp; z \in \mathbb{R}^n
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \min\nolimits_{x} &amp; x^\top Q x + (c-A^\top y)^\top x
\\
&amp; &amp; x \in \mathbb{R}^n
\end{aligned}
\end{equation}\]</p><p>This model admits a closed form solution, <span>$z = \frac{1}{2}Q^{-1}(c - A^\top y)$</span>. Furthermore, the closed form dual solution in this case is <span>$x=z$</span>.</p><h3 id="Decomposition-detection"><a class="docs-heading-anchor" href="#Decomposition-detection">Decomposition detection</a><a id="Decomposition-detection-1"></a><a class="docs-heading-anchor-permalink" href="#Decomposition-detection" title="Permalink"></a></h3><div class="admonition is-warning" id="Warning-16507bfbd932b9e3"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-16507bfbd932b9e3" title="Permalink"></a></header><div class="admonition-body"><p>The decomposition detection is very basic, based on minimizing the number of predicted dual variables. In some cases, it may actually be preferred to to predict more dual variables, if they are for some reason easier to learn. In that case, users should manually specify the decomposition.</p></div></div><p>L2ODLL automatically detects the decomposition to use based on the model. The current detection logic is as follows:</p><ul><li>If all variables have finite upper and lower bounds, use the bounded decomposition.</li><li>If all variables have a quadratic objective term, use the convex QP decomposition.</li><li>Otherwise, use the generic decomposition.</li></ul><p>The order of preference is to maximize the number of completed dual variables among the closed-form solutions, and if no closed-form solution is available, to use the generic decomposition. Thus, the bounded decomposition is preferred over the convex QP decomposition, as illustrated by the following example.</p><h4 id="Bounded-with-quadratic-objective"><a class="docs-heading-anchor" href="#Bounded-with-quadratic-objective">Bounded with quadratic objective</a><a id="Bounded-with-quadratic-objective-1"></a><a class="docs-heading-anchor-permalink" href="#Bounded-with-quadratic-objective" title="Permalink"></a></h4><p>In the case where bounded decomposition is used with a model that has a quadratic objective, L2ODLL prefers the bounded decomposition, leading to the following models.</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \min\nolimits_{x} &amp; x^\top Q x + c^\top x
\\
&amp; \;\;\text{s.t.} &amp; Ax + b \in \mathcal{C}
\\
&amp; &amp; l \leq x \leq u
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \max\nolimits_{w,y,z_l,z_u} &amp; - b^\top y - w^\top Q w - l^\top z_l - u^\top z_u
\\
&amp; \;\;\text{s.t.} &amp; A^\top y + 2Qw + z_l + z_u = c
\\
&amp; &amp; y \in \mathcal{C}^*,\; w \in \mathbb{R}^n,\; z_l \in \mathbb{R}_+^n,\; z_u \in \mathbb{R}_-^n
\end{aligned}
\end{equation}\]</p><p>Then, the completion model is:</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \max\nolimits_{z_l,z_u} &amp; - l^\top z_l - u^\top z_u - b^\top y - w^\top Q w
\\
&amp; \;\;\text{s.t.} &amp; z_l + z_u = c - A^\top y - 2Qw   
\\
&amp; &amp; z_l \in \mathbb{R}_+^n,\; z_u \in \mathbb{R}_-^n
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \min\nolimits_{x} &amp; (c-A^\top y - 2Qw)^\top x
\\
&amp; &amp; l \leq x \leq u
\end{aligned}
\end{equation}\]</p><p>This model admits a closed form solution, <span>$z_l = |c-A^\top y-2Qw|^+$</span> and <span>$z_u = -|c-A^\top y-2Qw|^-$</span>. Furthermore, the <span>$x$</span> that defines the (sub-)gradient is given element-wise by <span>$l$</span> if <span>$c-A^\top y-2Qw &gt; 0$</span>, <span>$u$</span> if <span>$c-A^\top y-2Qw &lt; 0$</span>, and <span>$x\in[l,u]$</span> otherwise. Note that the gradient of the objective with respect to <span>$w$</span> is <span>$\nabla_w = -(Q+Q^\top)w - 2Q^\top x$</span>.</p><p>This completes <span>$2n$</span> dual variables, leaving the neural network to predict <span>$m+n$</span> dual variables.</p><p>Consider the convex QP decomposition in this case:</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \min\nolimits_{x} &amp; x^\top Q x + c^\top x
\\
&amp; \;\;\text{s.t.} &amp; Ax + b \in \mathcal{C}
\\
&amp; &amp; l \leq x \leq u
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \max\nolimits_{w,y,z_l,z_u} &amp; - b^\top y - w^\top Q w - l^\top z_l - u^\top z_u
\\
&amp; \;\;\text{s.t.} &amp; A^\top y + 2Qw + z_l + z_u = c
\\
&amp; &amp; y \in \mathcal{C}^*,\; w \in \mathbb{R}^n,\; z_l \in \mathbb{R}_+^n,\; z_u \in \mathbb{R}_-^n
\end{aligned}
\end{equation}\]</p><p>Then, the completion model is:</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \max\nolimits_{w} &amp; - w^\top Q w - b^\top y - l^\top z_l - u^\top z_u 
\\
&amp; \;\;\text{s.t.} &amp; Qw = \frac{1}{2}(c - A^\top y - z_l - z_u)   
\\
&amp; &amp; w \in \mathbb{R}^n
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \min\nolimits_{x} &amp; x^\top Q x + (c-A^\top y - z_l - z_u)^\top x
\\
&amp; &amp; x \in \mathbb{R}^n
\end{aligned}
\end{equation}\]</p><p>This model admits a closed form solution, <span>$w = \frac{1}{2}Q^{-1}(c - A^\top y - z_l - z_u)$</span>. Furthermore, the closed form dual solution in this case is <span>$x=w$</span>.</p><p>This completes <span>$n$</span> dual variables, leaving the neural network to predict <span>$m+2n$</span> dual variables.</p><p>Naturally, one may consider using both decompositions, i.e. to predict only the <span>$y$</span> variables and to recover <span>$w$</span>, <span>$z_l$</span>, and <span>$z_u$</span>. Let us consider this case:</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \min\nolimits_{x} &amp; x^\top Q x + c^\top x
\\
&amp; \;\;\text{s.t.} &amp; Ax + b \in \mathcal{C}
\\
&amp; &amp; l \leq x \leq u
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \max\nolimits_{w,y,z_l,z_u} &amp; - b^\top y - w^\top Q w - l^\top z_l - u^\top z_u
\\
&amp; \;\;\text{s.t.} &amp; A^\top y + 2Qw + z_l + z_u = c
\\
&amp; &amp; y \in \mathcal{C}^*,\; w \in \mathbb{R}^n,\; z_l \in \mathbb{R}_+^n,\; z_u \in \mathbb{R}_-^n
\end{aligned}
\end{equation}\]</p><p>Then, the completion model is:</p><p class="math-container">\[\begin{equation}
\begin{aligned}
&amp; \max\nolimits_{w,z_l,z_u} &amp; - w^\top Q w - l^\top z_l - u^\top z_u - b^\top y
\\
&amp; \;\;\text{s.t.} &amp; 2Qw + z_l + z_u = c - A^\top y
\\
&amp; &amp; w \in \mathbb{R}^n,\; z_l \in \mathbb{R}_+^n,\; z_u \in \mathbb{R}_-^n
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
&amp; \min\nolimits_{x} &amp; x^\top Q x + (c-A^\top y)^\top x
\\
&amp; &amp; l \leq x \leq u
\end{aligned}
\end{equation}\]</p><p>This is an <span>$n$</span>-dimensional box-constrained convex QP, for which there is no closed form solution. Note that by using a custom generic decomposition, L2ODLL can still be used to set up this problem and solve it using a JuMP-compatible QP solver.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../public/">Reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.12.0 on <span class="colophon-date" title="Wednesday 11 June 2025 01:38">Wednesday 11 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
