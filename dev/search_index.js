var documenterSearchIndex = {"docs":
[{"location":"background/decomposition_detection/#Decomposition-detection","page":"Decomposition detection","title":"Decomposition detection","text":"","category":"section"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"warning: Warning\nThe decomposition detection is very basic, based on minimizing the number of predicted dual variables. In some cases, it may actually be preferred to to predict more dual variables, if they are for some reason easier to learn. In that case, users should manually specify the decomposition.","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"L2ODLL automatically detects the decomposition to use based on the model. The current detection logic is as follows:","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"If all variables have finite upper and lower bounds, use the bounded decomposition.\nIf all variables have a quadratic objective term, use the convex QP decomposition.\nOtherwise, use the generic decomposition.","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"The order of preference is to maximize the number of completed dual variables among the closed-form solutions, and if no closed-form solution is available, to use the generic decomposition. Thus, the bounded decomposition is preferred over the convex QP decomposition, as illustrated by the following example.","category":"page"},{"location":"background/decomposition_detection/#Bounded-with-quadratic-objective","page":"Decomposition detection","title":"Bounded with quadratic objective","text":"","category":"section"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"In the case where bounded decomposition is used with a model that has a quadratic objective, L2ODLL prefers the bounded decomposition, leading to the following models.","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"beginequation\nbeginaligned\n minnolimits_x  x^top Q x + c^top x\n\n textst  Ax + b in mathcalC\n\n  l leq x leq u\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_wyz_lz_u  - b^top y - w^top Q w - l^top z_l - u^top z_u\n\n textst  A^top y + 2Qw + z_l + z_u = c\n\n  y in mathcalC^* w in mathbbR^n z_l in mathbbR_+^n z_u in mathbbR_-^n\nendaligned\nendequation","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"Then, the completion model is:","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"beginequation\nbeginaligned\n maxnolimits_z_lz_u  - l^top z_l - u^top z_u - b^top y - w^top Q w\n\n textst  z_l + z_u = c - A^top y - 2Qw   \n\n  z_l in mathbbR_+^n z_u in mathbbR_-^n\nendaligned\nquadquadquadquad\nbeginaligned\n minnolimits_x  (c-A^top y - 2Qw)^top x\n\n  l leq x leq u\nendaligned\nendequation","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"This model admits a closed form solution, z_l = c-A^top y-2Qw^+ and z_u = -c-A^top y-2Qw^-. Furthermore, the x that defines the (sub-)gradient is given element-wise by l if c-A^top y-2Qw  0, u if c-A^top y-2Qw  0, and xinlu otherwise. Note that the gradient of the objective with respect to w is nabla_w = -(Q+Q^top)w - 2Q^top x.","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"This completes 2n dual variables, leaving the neural network to predict m+n dual variables.","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"Consider the convex QP decomposition in this case:","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"beginequation\nbeginaligned\n minnolimits_x  x^top Q x + c^top x\n\n textst  Ax + b in mathcalC\n\n  l leq x leq u\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_wyz_lz_u  - b^top y - w^top Q w - l^top z_l - u^top z_u\n\n textst  A^top y + 2Qw + z_l + z_u = c\n\n  y in mathcalC^* w in mathbbR^n z_l in mathbbR_+^n z_u in mathbbR_-^n\nendaligned\nendequation","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"Then, the completion model is:","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"beginequation\nbeginaligned\n maxnolimits_w  - w^top Q w - b^top y - l^top z_l - u^top z_u \n\n textst  Qw = frac12(c - A^top y - z_l - z_u)   \n\n  w in mathbbR^n\nendaligned\nquadquadquadquad\nbeginaligned\n minnolimits_x  x^top Q x + (c-A^top y - z_l - z_u)^top x\n\n  x in mathbbR^n\nendaligned\nendequation","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"This model admits a closed form solution, w = frac12Q^-1(c - A^top y - z_l - z_u). Furthermore, the closed form dual solution in this case is x=w.","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"This completes n dual variables, leaving the neural network to predict m+2n dual variables.","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"Naturally, one may consider using both decompositions, i.e. to predict only the y variables and to recover w, z_l, and z_u. Let us consider this case:","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"beginequation\nbeginaligned\n minnolimits_x  x^top Q x + c^top x\n\n textst  Ax + b in mathcalC\n\n  l leq x leq u\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_wyz_lz_u  - b^top y - w^top Q w - l^top z_l - u^top z_u\n\n textst  A^top y + 2Qw + z_l + z_u = c\n\n  y in mathcalC^* w in mathbbR^n z_l in mathbbR_+^n z_u in mathbbR_-^n\nendaligned\nendequation","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"Then, the completion model is:","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"beginequation\nbeginaligned\n maxnolimits_wz_lz_u  - w^top Q w - l^top z_l - u^top z_u - b^top y\n\n textst  2Qw + z_l + z_u = c - A^top y\n\n  w in mathbbR^n z_l in mathbbR_+^n z_u in mathbbR_-^n\nendaligned\nquadquadquadquad\nbeginaligned\n minnolimits_x  x^top Q x + (c-A^top y)^top x\n\n  l leq x leq u\nendaligned\nendequation","category":"page"},{"location":"background/decomposition_detection/","page":"Decomposition detection","title":"Decomposition detection","text":"This is an n-dimensional box-constrained convex QP, for which there is no closed form solution. Note that by using a custom generic decomposition, L2ODLL can still be used to set up this problem and solve it using a JuMP-compatible QP solver.","category":"page"},{"location":"background/decompositions/#Decompositions","page":"Decompositions","title":"Decompositions","text":"","category":"section"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"In DLL, the primal constraints (dual variables) are decomposed into a predicted set and a completed set. Consider the primal-dual pair:","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"beginequation\nbeginaligned\n minnolimits_x  c^top x\n\n textst  Ax + b in mathcalC\n\n  x in mathbbR^n\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_y  - b^top y\n\n textst  A^top y = c\n\n  y in mathcalC^*\nendaligned\nendequation","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"After the decomposition, we have:","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"beginequation\nbeginaligned\n minnolimits_x  c^top x\n\n textst  Ax + b in mathcalC\n\n phantomtextst  Hx + h in mathcalK\n\n  x in mathbbR^n\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_y  - b^top y\n\n textst  A^top y + H^top z = c\n\n  y in mathcalC^* z in mathcalK^*\nendaligned\nendequation","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"Then, the completion model is:","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"beginequation\nbeginaligned\n maxnolimits_z  - h^top z - b^top y\n\n textst  H z = c - A^top y\n\n  z in mathcalK^*\nendaligned\nquadquadquadquad\nbeginaligned\n minnolimits_x  (c-A^top y)^top x\n\n phantomtextst  Hx + h in mathcalK\n\n  x in mathbbR^n\nendaligned\nendequation","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"To train the neural network, we need the gradient of the optimal value with respect to the predicted y. This is nabla_y = -b-Ax where x is the optimal dual solution corresponding to the affine constraints in the completion model. In the special cases below, we specify just the expression for x in this formula.","category":"page"},{"location":"background/decompositions/#Bounded-Decomposition","page":"Decompositions","title":"Bounded Decomposition","text":"","category":"section"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"When all primal variables have finite upper and lower bounds, a natural way to decompose the constraints is to have z correspond to the bound constraints, and y correspond to the main constraints, i.e.","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"beginequation\nbeginaligned\n minnolimits_x  c^top x\n\n textst  Ax + b in mathcalC\n\n  l leq x leq u\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_yz_lz_u  - b^top y - l^top z_l - u^top z_u\n\n textst  A^top y + z_l + z_u = c\n\n  y in mathcalC^* z_l in mathbbR_+^n z_u in mathbbR_-^n\nendaligned\nendequation","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"Then, the completion model is:","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"beginequation\nbeginaligned\n maxnolimits_z_lz_u  - l^top z_l - u^top z_u - b^top y\n\n textst  z_l + z_u = c - A^top y\n\n  z_l in mathbbR_+^n z_u in mathbbR_-^n\nendaligned\nquadquadquadquad\nbeginaligned\n minnolimits_x  (c-A^top y)^top x\n\n  l leq x leq u\nendaligned\nendequation","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"This model admits a closed form solution, z_l = c-A^top y^+ and z_u = -c-A^top y^-. Furthermore, the x that defines the (sub-)gradient is given element-wise by l if c-A^top y  0, u if c-A^top y  0, and xinlu otherwise.","category":"page"},{"location":"background/decompositions/#(Strictly)-Convex-QP","page":"Decompositions","title":"(Strictly) Convex QP","text":"","category":"section"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"In the convex QP case, the primal has a strictly convex quadratic objective function, i.e. Qsucc 0. In that case it is natural to use the main constraints as the predicted set and to complete the quadratic slack dual variables.","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"beginequation\nbeginaligned\n minnolimits_x  x^top Q x + c^top x\n\n textst  Ax + b in mathcalC\n\n  x in mathbbR^n\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_y  - b^top y - z^top Q z\n\n textst  A^top y + 2Qz = c\n\n  y in mathcalC^* z in mathbbR^n\nendaligned\nendequation","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"Then, the completion model is:","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"beginequation\nbeginaligned\n maxnolimits_z  - z^top Q z - b^top y\n\n textst  Q z = frac12(c - A^top y)\n\n  z in mathbbR^n\nendaligned\nquadquadquadquad\nbeginaligned\n minnolimits_x  x^top Q x + (c-A^top y)^top x\n\n  x in mathbbR^n\nendaligned\nendequation","category":"page"},{"location":"background/decompositions/","page":"Decompositions","title":"Decompositions","text":"This model admits a closed form solution, z = frac12Q^-1(c - A^top y). Furthermore, the closed form dual solution in this case is x=z.","category":"page"},{"location":"public/#L2ODLL.BoundDecomposition-Tuple{JuMP.Model}","page":"Reference","title":"L2ODLL.BoundDecomposition","text":"BoundDecomposition(model::JuMP.Model)\n\nCreate a decomposition using z for bound constraints and y for all other constraints.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.ConvexQP-Tuple{JuMP.Model}","page":"Reference","title":"L2ODLL.ConvexQP","text":"ConvexQP(model::JuMP.Model)\n\nCreate a decomposition using z for the quadratic slacks and y for all constraints.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.GenericDecomposition-Tuple{JuMP.Model, Vector{JuMP.ConstraintRef}}","page":"Reference","title":"L2ODLL.GenericDecomposition","text":"GenericDecomposition(model::JuMP.Model, y_ref::Vector{JuMP.ConstraintRef})\n\nCreate a decomposition using z for all constraints except y_ref.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.build_cache-Tuple{JuMP.Model, L2ODLL.AbstractDecomposition}","page":"Reference","title":"L2ODLL.build_cache","text":"build_cache(model::JuMP.Model, decomposition::AbstractDecomposition;\n    optimizer=nothing, proj_fn=nothing, dll_layer_builder=nothing\n)\n\nBuild the DLLCache for the given model and decomposition.     In this lower-level function (compared to decompose!), users can set     custom projection functions via proj_fn and custom DLL layer builders     via dll_layer_builder.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.decompose!-Tuple{JuMP.Model, L2ODLL.AbstractDecomposition}","page":"Reference","title":"L2ODLL.decompose!","text":"decompose!(model::JuMP.Model, decomposition::AbstractDecomposition)\n\nBuild the DLL functions using the given decomposition.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.decompose!-Tuple{JuMP.Model}","page":"Reference","title":"L2ODLL.decompose!","text":"decompose!(model::JuMP.Model)\n\nDetect the best decomposition and build the DLL functions.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.dual_objective-Tuple{JuMP.Model, Any, Any}","page":"Reference","title":"L2ODLL.dual_objective","text":"dual_objective(model::JuMP.Model, y_predicted, param_value)\n\nEvaluate the dual objective function (projection and completion).\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.dual_objective_gradient-Tuple{JuMP.Model, Any, Any}","page":"Reference","title":"L2ODLL.dual_objective_gradient","text":"dual_objective_gradient(model::JuMP.Model, y_predicted, param_value; ad_type::ADTypes.AbstractADType=DI.AutoForwardDiff())\n\nEvaluate the gradient of the dual objective function with respect to the predicted dual variables.     This includes both the projection and the completion steps.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.flatten_y-Tuple{AbstractVector}","page":"Reference","title":"L2ODLL.flatten_y","text":"flatten_y(y::AbstractVector)\n\nFlatten a vector of y variables into a single vector, i.e. Vector{Vector{Float64}} -> Vector{Float64}.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.get_cache-Tuple{JuMP.Model}","page":"Reference","title":"L2ODLL.get_cache","text":"get_cache(model::JuMP.Model)\n\nGet the DLLCache for the model. Must have called decompose! first.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.get_y-Tuple{JuMP.Model}","page":"Reference","title":"L2ODLL.get_y","text":"get_y(model::JuMP.Model)\n\nGet the primal constraints corresponding to the y variables in the decomposition.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.get_y_dual-Tuple{JuMP.Model}","page":"Reference","title":"L2ODLL.get_y_dual","text":"get_y_dual(model::JuMP.Model)\n\nGet the dual variables corresponding to the y variables in the decomposition.     These are VariableRefs belonging to the dual model, not the passed-in model.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.jump_builder-Tuple{L2ODLL.AbstractDecomposition, Function, JuMP.Model, Any}","page":"Reference","title":"L2ODLL.jump_builder","text":"jump_builder(decomposition::AbstractDecomposition, proj_fn::Function, dual_model::JuMP.Model, optimizer; silent=true)\n\nBuild the completion function using JuMP to solve the model.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.make_completion_model-Tuple{L2ODLL.DLLCache}","page":"Reference","title":"L2ODLL.make_completion_model","text":"make_completion_model(cache::DLLCache)\n\nCreate a JuMP model for the dual completion step.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.make_proj_fn-Tuple{L2ODLL.AbstractDecomposition, JuMP.Model}","page":"Reference","title":"L2ODLL.make_proj_fn","text":"make_proj_fn(decomposition::AbstractDecomposition, dual_model::JuMP.Model)\n\nCreate a function that projects the raw dual variable predictions onto their dual cone constraints.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.unflatten_y-Tuple{AbstractVector, AbstractVector{Int64}}","page":"Reference","title":"L2ODLL.unflatten_y","text":"unflatten_y(y::AbstractVector, y_shape::AbstractVector{Int})\n\nUnflatten a vector of flattened y variables into a vector of vectors, i.e. Vector{Float64} -> Vector{Vector{Float64}}.\n\n\n\n\n\n","category":"method"},{"location":"public/#L2ODLL.y_shape-Tuple{JuMP.Model}","page":"Reference","title":"L2ODLL.y_shape","text":"y_shape(model::JuMP.Model)\n\nGet the shape of the y variables in the decomposition.     This is a Vector{Int} where each entry is the number of dual variables for that constraint.\n\n\n\n\n\n","category":"method"},{"location":"#L2ODLL.jl","page":"Home","title":"L2ODLL.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"warning: Warning\nThis documentation is a work in progress. Please open an issue if content is missing / erroneous.","category":"page"},{"location":"","page":"Home","title":"Home","text":"L2ODLL.jl implements the Dual Lagrangian Learning (DLL) method of Tanneau and Hentenryck (2024) using JuMP.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"import Pkg\nPkg.add(; url=\"https://github.com/LearningToOptimize/L2ODLL.jl\")","category":"page"},{"location":"#Usage","page":"Home","title":"Usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package simplifies the implementation of DLL by taking as input a primal JuMP model, then automatically generating the dual projection and completion functions which can be used in the training and inference of DLL models. The basic usage is as follows:","category":"page"},{"location":"#Define-your-(primal)-model-using-JuMP","page":"Home","title":"Define your (primal) model using JuMP","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For the purposes of this example, we'll use a portfolio optimization problem.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using JuMP, LinearAlgebra\n\nmodel = Model()\n\n# define constant problem data\nΣ = [166 34 58; 34 64 4; 58 4 100] / 100^2\nN = size(Σ, 1)\n\n# define variables\n@variable(model, x[1:N])\nset_lower_bound.(x, 0)  # we explicitly set upper and lower bounds\nset_upper_bound.(x, 1)  #   in order to use the BoundDecomposition\n\n# define parameteric problem data\nμ0 = randn(N)\nγ0 = rand()\n@variable(model, μ[1:N] in MOI.Parameter.(μ0))\n@variable(model, γ in MOI.Parameter(γ0))\n\n# define constraints\n@constraint(model, simplex, sum(x) == 1)\n@constraint(model, risk, [γ; cholesky(Σ).L * x] in SecondOrderCone())\n\n# define objective\n@objective(model, Max, dot(μ,x))","category":"page"},{"location":"#Decompose-and-build-the-functions","page":"Home","title":"Decompose and build the functions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Since all the variables have finite bounds, L2ODLL will automatically pick the BoundDecomposition.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using L2ODLL\n\nL2ODLL.decompose!(model)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Now, L2ODLL has automatically generated the dual projection and completion layer. To compute the dual objective value and gradient with respect to the prediction, use:","category":"page"},{"location":"","page":"Home","title":"Home","text":"param_value = ... # some values for μ and γ\ny_predicted = nn(param_value) # e.g. neural network inference\n\ndobj = L2ODLL.dual_objective(model, y_predicted, param_value)\ndobj_wrt_y = L2ODLL.dual_objective_gradient(model, y_predicted, param_value)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This also works with batches, using broadcasting:","category":"page"},{"location":"","page":"Home","title":"Home","text":"dobj = L2ODLL.dual_objective.(model, y_predicted_batch, param_value_batch)\ndobj_wrt_y = L2ODLL.dual_objective_gradient.(model, y_predicted_batch, param_value_batch)","category":"page"},{"location":"","page":"Home","title":"Home","text":"warning: Warning\nThese functions currently run on the CPU. A batched GPU-friendly version is coming soon.","category":"page"}]
}
