var documenterSearchIndex = {"docs":
[{"location":"#L2ODLL.jl","page":"Home","title":"L2ODLL.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"warning: Warning\nThis documentation is a work in progress. Please open an issue if content is missing / erroneous","category":"page"},{"location":"","page":"Home","title":"Home","text":"L2ODLL.jl implements the Dual Lagrangian Learning (DLL) method of Tanneau and Hentenryck (2024) using JuMP.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"import Pkg\nPkg.add(; url=\"https://github.com/LearningToOptimize/L2ODLL.jl\")","category":"page"},{"location":"#Math-Background","page":"Home","title":"Math Background","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package simplifies the implementation of DLL by taking as input a primal JuMP model, then automatically generating the dual projection and completion functions which can be used in the training and inference of DLL models.","category":"page"},{"location":"#Decomposition","page":"Home","title":"Decomposition","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In DLL, the primal constraints (dual variables) are decomposed into a predicted set and a completed set. Consider the primal-dual pair:","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginequation\nbeginaligned\n minnolimits_x  c^top x\n\n textst  Ax + b in mathcalC\n\n  x in mathbbR^n\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_y  - b^top y\n\n textst  A^top y = c\n\n  y in mathcalC^*\nendaligned\nendequation","category":"page"},{"location":"","page":"Home","title":"Home","text":"After the decomposition, we have:","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginequation\nbeginaligned\n minnolimits_x  c^top x\n\n textst  Ax + b in mathcalC\n\n phantomtextst  Hx + h in mathcalK\n\n  x in mathbbR^n\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_y  - b^top y\n\n textst  A^top y + H^top z = c\n\n  y in mathcalC^* z in mathcalK^*\nendaligned\nendequation","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, the completion model is:","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginequation\nbeginaligned\n maxnolimits_z  - h^top z - b^top y\n\n textst  H z = c - A^top y\n\n  z in mathcalK^*\nendaligned\nendequation","category":"page"},{"location":"","page":"Home","title":"Home","text":"To train the neural network, we need the gradient of the optimal value with respect to the predicted y. This is nabla_y = -b-Ax where x is the optimal dual solution corresponding to the affine constraints in the completion model. In the special cases below, we specify just the expression for x in this formula.","category":"page"},{"location":"#Bounded-Decomposition","page":"Home","title":"Bounded Decomposition","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"When all primal variables have finite upper and lower bounds, a natural way to decompose the constraints is to have z correspond to the bound constraints, and y correspond to the main constraints, i.e.","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginequation\nbeginaligned\n minnolimits_x  c^top x\n\n textst  Ax + b in mathcalC\n\n  l leq x leq u\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_yz_lz_u  - b^top y - l^top z_l - u^top z_u\n\n textst  A^top y + I z_l + I z_u = c\n\n  y in mathcalC^* z_l in mathbbR_+^n z_u in mathbbR_-^n\nendaligned\nendequation","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, the completion model is:","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginequation\nbeginaligned\n maxnolimits_z_lz_u  - l^top z_l - u^top z_u - b^top y\n\n textst  I z_l + I z_u = c - A^top y\n\n  z_l in mathbbR_+^n z_u in mathbbR_-^n\nendaligned\nendequation","category":"page"},{"location":"","page":"Home","title":"Home","text":"This model admits a closed form solution, z_l = c-A^top y^+ and z_u = -c-A^top y^-. Furthermore, the x that defines the (sub-)gradient is given element-wise by l if z_l  0, u if z_u  0, and xinlu otherwise.","category":"page"},{"location":"#(Strictly)-Convex-QP","page":"Home","title":"(Strictly) Convex QP","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In the convex QP case, the primal has a strictly convex quadratic objective function, i.e. Qsucc 0. In that case it is natural to use the main constraints as the predicted set and to complete the quadratic slack dual variables.","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginequation\nbeginaligned\n minnolimits_x  x^top Q x + c^top x\n\n textst  Ax + b in mathcalC\n\n  x in mathbbR^n\nendaligned\nquadquadquadquad\nbeginaligned\n maxnolimits_y  - b^top y - z^top Q z\n\n textst  A^top y + Q^top z = c\n\n  y in mathcalC^* z in mathbbR^n\nendaligned\nendequation","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, the completion model is:","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginequation\nbeginaligned\n maxnolimits_z  - z^top Q z - b^top y\n\n textst  Q z = c - A^top y\n\n  z in mathbbR^n\nendaligned\nendequation","category":"page"},{"location":"","page":"Home","title":"Home","text":"This model admits a closed form solution, z = Q^-1(c - A^top y). Furthermore, the closed form dual solution in this case is x=z.","category":"page"}]
}
